{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c10c85e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-11T15:36:12.160541Z",
     "iopub.status.busy": "2024-12-11T15:36:12.160095Z",
     "iopub.status.idle": "2024-12-11T15:36:50.032184Z",
     "shell.execute_reply": "2024-12-11T15:36:50.031018Z"
    },
    "papermill": {
     "duration": 37.879544,
     "end_time": "2024-12-11T15:36:50.034784",
     "exception": false,
     "start_time": "2024-12-11T15:36:12.155240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "日期範圍: 1001 - 1698\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "features = [\"feature_06\", \"feature_36\", \"feature_04\", \"feature_56\", \"feature_19\", \"feature_59\", \n",
    "            \"feature_25\", \"feature_45\", \"feature_60\", \"feature_58\", \"feature_39\", \"feature_66\",\n",
    "            \"feature_08\", \"feature_68\", \"feature_52\", \"feature_70\", \"feature_48\", \"feature_24\", \n",
    "            \"feature_65\", \"feature_74\"]\n",
    "\n",
    "class CONFIG:\n",
    "    target_col = \"responder_6\"\n",
    "    start_dt = 1000\n",
    "    selected_columns = [\"date_id\", 'time_id', 'symbol_id', 'responder_6', 'weight'] + features\n",
    "\n",
    "\n",
    "def load_and_split_data(parquet_path, config):\n",
    "    df = pl.scan_parquet(parquet_path).select(\n",
    "        config.selected_columns\n",
    "    ).select(\n",
    "        pl.int_range(pl.len(), dtype=pl.UInt32).alias(\"id\"),\n",
    "        pl.all(),\n",
    "    ).filter(\n",
    "        pl.col(\"date_id\").gt(config.start_dt)\n",
    "    ).collect()\n",
    "    \n",
    "    # Create lag feature\n",
    "    df = df.sort(['symbol_id', 'date_id', 'time_id'])\n",
    "    \n",
    "    \n",
    "   \n",
    "    print(f\"日期範圍: {df['date_id'].min()} - {df['date_id'].max()}\")\n",
    "    return df\n",
    "\n",
    "# 使用示例\n",
    "df = load_and_split_data(\n",
    "    \"/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet\",\n",
    "    CONFIG\n",
    ")\n",
    "df = df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9290b49c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T15:36:50.041069Z",
     "iopub.status.busy": "2024-12-11T15:36:50.040552Z",
     "iopub.status.idle": "2024-12-11T15:36:50.050015Z",
     "shell.execute_reply": "2024-12-11T15:36:50.048788Z"
    },
    "papermill": {
     "duration": 0.015318,
     "end_time": "2024-12-11T15:36:50.052478",
     "exception": false,
     "start_time": "2024-12-11T15:36:50.037160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "multiprocessing.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acd307f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T15:36:50.059209Z",
     "iopub.status.busy": "2024-12-11T15:36:50.058263Z",
     "iopub.status.idle": "2024-12-11T15:37:16.147031Z",
     "shell.execute_reply": "2024-12-11T15:37:16.145348Z"
    },
    "papermill": {
     "duration": 26.095922,
     "end_time": "2024-12-11T15:37:16.150765",
     "exception": false,
     "start_time": "2024-12-11T15:36:50.054843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: Using fork() can cause Polars to deadlock in the child process.\n",
      "In addition, using fork() with Python in general is a recipe for mysterious\n",
      "deadlocks and crashes.\n",
      "\n",
      "The most likely reason you are seeing this error is because you are using the\n",
      "multiprocessing module on Linux, which uses fork() by default. This will be\n",
      "fixed in Python 3.14. Until then, you want to use the \"spawn\" context instead.\n",
      "\n",
      "See https://docs.pola.rs/user-guide/misc/multiprocessing/ for details.\n",
      "\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-forecasting\r\n",
      "  Downloading pytorch_forecasting-1.2.0-py3-none-any.whl.metadata (13 kB)\r\n",
      "Requirement already satisfied: numpy<=3.0.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-forecasting) (1.26.4)\r\n",
      "Requirement already satisfied: torch!=2.0.1,<3.0.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-forecasting) (2.4.0+cpu)\r\n",
      "Collecting lightning<3.0.0,>=2.0.0 (from pytorch-forecasting)\r\n",
      "  Downloading lightning-2.4.0-py3-none-any.whl.metadata (38 kB)\r\n",
      "Requirement already satisfied: scipy<2.0,>=1.8 in /opt/conda/lib/python3.10/site-packages (from pytorch-forecasting) (1.14.1)\r\n",
      "Requirement already satisfied: pandas<3.0.0,>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-forecasting) (2.2.3)\r\n",
      "Requirement already satisfied: scikit-learn<2.0,>=1.2 in /opt/conda/lib/python3.10/site-packages (from pytorch-forecasting) (1.2.2)\r\n",
      "Requirement already satisfied: PyYAML<8.0,>=5.4 in /opt/conda/lib/python3.10/site-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (6.0.2)\r\n",
      "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (2024.9.0)\r\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (0.11.9)\r\n",
      "Requirement already satisfied: packaging<25.0,>=20.0 in /opt/conda/lib/python3.10/site-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (21.3)\r\n",
      "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.6.0)\r\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (4.66.4)\r\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (4.12.2)\r\n",
      "Requirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (from lightning<3.0.0,>=2.0.0->pytorch-forecasting) (2.4.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0.0,>=1.3.0->pytorch-forecasting) (2024.1)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2.0,>=1.2->pytorch-forecasting) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2.0,>=1.2->pytorch-forecasting) (3.5.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.15.1)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (1.13.1)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (3.1.4)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (3.9.5)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities<2.0,>=0.10.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (70.0.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging<25.0,>=20.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (3.1.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=1.3.0->pytorch-forecasting) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch!=2.0.1,<3.0.0,>=2.0.0->pytorch-forecasting) (1.3.0)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (23.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (1.9.4)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (4.0.3)\r\n",
      "Requirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch-forecasting) (3.7)\r\n",
      "Downloading pytorch_forecasting-1.2.0-py3-none-any.whl (181 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.9/181.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading lightning-2.4.0-py3-none-any.whl (810 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.0/811.0 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: lightning, pytorch-forecasting\r\n",
      "Successfully installed lightning-2.4.0 pytorch-forecasting-1.2.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-forecasting\n",
    "!pip --quiet install pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "076ffcce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T15:37:16.160940Z",
     "iopub.status.busy": "2024-12-11T15:37:16.160459Z",
     "iopub.status.idle": "2024-12-11T15:41:47.847489Z",
     "shell.execute_reply": "2024-12-11T15:41:47.845543Z"
    },
    "papermill": {
     "duration": 271.710493,
     "end_time": "2024-12-11T15:41:47.865406",
     "exception": false,
     "start_time": "2024-12-11T15:37:16.154913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "切分date_id: 1559\n",
      "對應的sequential_id: 540144\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import MAE, SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "\n",
    "columns_with_na = df.columns[df.isna().any()].tolist()\n",
    "for column in columns_with_na:\n",
    "    df[column] = df.groupby('symbol_id')[column].ffill()\n",
    "    df[column] = df.groupby('symbol_id')[column].bfill()\n",
    "    df[column] = df[column].fillna(0)\n",
    "\n",
    "def create_sequential_id_with_duplicates(df):\n",
    "    \"\"\"\n",
    "    將 date_id 和 time_id 合併成連續的 ID，相同的組合會得到相同的 ID\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): 包含 date_id、time_id 的 DataFrame\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: 添加了 sequential_id 的 DataFrame\n",
    "    \"\"\"\n",
    "    # 獲取唯一的 (date_id, time_id) 組合並排序\n",
    "    unique_combinations = (\n",
    "        df[['date_id', 'time_id']]\n",
    "        .drop_duplicates()\n",
    "        .sort_values(['date_id', 'time_id'])\n",
    "    )\n",
    "    \n",
    "    # 為唯一組合創建 ID 映射字典\n",
    "    id_mapping = {\n",
    "        (date_id, time_id): i \n",
    "        for i, (date_id, time_id) in enumerate(\n",
    "            zip(unique_combinations['date_id'], \n",
    "                unique_combinations['time_id'])\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    # 為每一行添加 sequential_id\n",
    "    df['sequential_id'] = df.apply(\n",
    "        lambda row: id_mapping[(row['date_id'], row['time_id'])], \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    return df.sort_values(['symbol_id', 'sequential_id'])\n",
    "df = create_sequential_id_with_duplicates(df)\n",
    "# 1. 獲取唯一的date_id並排序\n",
    "unique_dates = sorted(df['date_id'].unique())\n",
    "\n",
    "# 2. 計算10%分位點的索引\n",
    "cutoff_index = int(len(unique_dates) * 0.8)  # 取90%位置，即最後10%的起始點\n",
    "\n",
    "# 3. 獲取切分的date_id\n",
    "cutoff_date = unique_dates[cutoff_index]\n",
    "\n",
    "# 4. 找出對應的最小sequential_id\n",
    "cutoff_sequential_id = df[df['date_id'] >= cutoff_date]['sequential_id'].min()\n",
    "\n",
    "print(f\"切分date_id: {cutoff_date}\")\n",
    "print(f\"對應的sequential_id: {cutoff_sequential_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b2b5ca5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T15:41:47.879899Z",
     "iopub.status.busy": "2024-12-11T15:41:47.876888Z",
     "iopub.status.idle": "2024-12-11T15:45:10.767599Z",
     "shell.execute_reply": "2024-12-11T15:45:10.766399Z"
    },
    "papermill": {
     "duration": 202.900897,
     "end_time": "2024-12-11T15:45:10.770555",
     "exception": false,
     "start_time": "2024-12-11T15:41:47.869658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['symbol_id'] = df['symbol_id'].astype(str)\n",
    "max_prediction_length = 10\n",
    "max_encoder_length = 500\n",
    "\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    df[lambda x: x.sequential_id <= cutoff_sequential_id],\n",
    "    time_idx=\"sequential_id\",\n",
    "    target=\"responder_6\",\n",
    "    group_ids=[\"symbol_id\"],\n",
    "    min_encoder_length=max_encoder_length // 2,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[\"symbol_id\"],\n",
    "    time_varying_known_reals=[\"date_id\", \"time_id\", 'sequential_id'],\n",
    "    time_varying_unknown_reals=features+['responder_6'],\n",
    "    weight = \"weight\",\n",
    "    #target_normalizer=GroupNormalizer(\n",
    "        #groups=[\"symbol_id\"], transformation=\"softplus\"\n",
    "    #),\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    "    allow_missing_timesteps=True,\n",
    ")\n",
    "\n",
    "# create validation set (predict=True) which means to predict the last max_prediction_length points in time\n",
    "# for each series\n",
    "validation = TimeSeriesDataSet.from_dataset(training, df, predict=True, stop_randomization=True)\n",
    "\n",
    "# create dataloaders for model\n",
    "batch_size = 128  # set this between 32 to 128\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9871156,
     "sourceId": 84493,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 545.790758,
   "end_time": "2024-12-11T15:45:14.937084",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-11T15:36:09.146326",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
